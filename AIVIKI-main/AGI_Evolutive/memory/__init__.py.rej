diff a/AIVIKI-main/AGI_Evolutive/memory/__init__.py b/AIVIKI-main/AGI_Evolutive/memory/__init__.py	(rejected hunks)
@@ -1,35 +1,35 @@
 # memory/__init__.py
 """
 Syst√®me de M√©moire Complet de l'AGI √âvolutive
 Int√®gre m√©moire de travail, √©pisodique, s√©mantique, proc√©durale et consolidation
 """
 
 import logging
 import math
 import random
-from typing import Any, Iterable
+from typing import Any, Iterable, TYPE_CHECKING
 try:
     import numpy as np  # type: ignore
 except Exception:  # pragma: no cover - lightweight fallback when numpy is absent
     class _FallbackNumpy:
         floating = float
 
         @staticmethod
         def isfinite(value: Any) -> bool:
             try:
                 return math.isfinite(float(value))
             except Exception:
                 return False
 
         @staticmethod
         def tanh(value: Any) -> float:
             try:
                 return math.tanh(float(value))
             except Exception:
                 return 0.0
 
         @staticmethod
         def clip(value: Any, low: float, high: float) -> float:
             try:
                 numeric = float(value)
             except Exception:
@@ -38,91 +38,94 @@ except Exception:  # pragma: no cover - lightweight fallback when numpy is absen
 
         @staticmethod
         def exp(value: Any) -> float:
             try:
                 return math.exp(float(value))
             except Exception:
                 return 0.0
 
         @staticmethod
         def var(values: Iterable[Any]) -> float:
             filtered = [float(v) for v in values if isinstance(v, (int, float))]
             if not filtered:
                 return 0.0
             mean = sum(filtered) / len(filtered)
             return sum((v - mean) ** 2 for v in filtered) / len(filtered)
 
         class random:  # type: ignore
             @staticmethod
             def random() -> float:
                 return random.random()
 
     np = _FallbackNumpy()  # type: ignore
 import time
 from collections import deque
 from datetime import datetime, timedelta
-from typing import Callable, Dict, List, Optional, Tuple, Union
+from typing import Callable, Dict, List, Optional, Tuple, Union, Mapping
 from dataclasses import dataclass, field
 from enum import Enum
 import heapq
 import json
 import hashlib
 
 try:
     from config.memory_flags import ENABLE_SALIENCE_SCORER, ENABLE_SUMMARIZER  # type: ignore
 except Exception:
     ENABLE_SALIENCE_SCORER, ENABLE_SUMMARIZER = True, True
 
 
 try:  # pragma: no cover - optional integration
     from memory.salience_scorer import SalienceScorer  # type: ignore
 except ModuleNotFoundError:  # pragma: no cover - fallback when package path differs
     try:
         from .salience_scorer import SalienceScorer  # type: ignore
     except Exception:  # pragma: no cover
         SalienceScorer = None
 except Exception:  # pragma: no cover
     SalienceScorer = None
 
 
 try:  # pragma: no cover - optional integration
     from memory.semantic_memory_manager import SemanticMemoryManager  # type: ignore
 except Exception:  # pragma: no cover
     SemanticMemoryManager = None
 
 
 from .adaptive import AdaptiveMemoryParameters, ThompsonBetaScheduler
 from .retrieval import MemoryRetrieval
 from .semantic_memory_manager import (
     SemanticMemoryManager as _SummarizationCoordinator,
     ProgressiveSummarizer,
     SummarizerConfig,
 )
 from .semantic_manager import SemanticMemoryManager as _ConceptMemoryManager
 from .alltime import LongTermMemoryHub
 from AGI_Evolutive.utils.llm_service import try_call_llm_dict
 
+if TYPE_CHECKING:  # pragma: no cover - hints only
+    from AGI_Evolutive.phenomenology import PhenomenalJournal, PhenomenalRecall
+
 LOGGER = logging.getLogger(__name__)
 
 __all__ = [
     "MemorySystem",
     "SemanticMemoryManager",
     "ProgressiveSummarizer",
     "SummarizerConfig",
     "LongTermMemoryHub",
 ]
 
 # Conserve the historical export name
 SemanticMemoryManager = _ConceptMemoryManager
 
 try:  # configuration optionnelle
     from config import memory_flags as _mem_flags
 except Exception:  # pragma: no cover - robuste si config absente
     _mem_flags = None  # type: ignore
 
 class MemoryType(Enum):
     """Types de m√©moire dans le syst√®me"""
     SENSORY = "sensorielle"
     WORKING = "travail"
     EPISODIC = "√©pisodique"
     SEMANTIC = "s√©mantique"
     PROCEDURAL = "proc√©durale"
@@ -188,50 +191,52 @@ class MemorySystem:
         if self.store is not None:
             try:
                 self.persistence = _SummarizationCoordinator(
                     memory_store=self.store,
                     concept_store=concept_store,
                     episodic_linker=episodic_linker,
                     consolidator=consolidator,
                     summarize_period_s=summarize_period_s,
                     summarizer_config=summarizer_config,
                     llm_summarize_fn=llm_summarize_fn,
                 )
             except Exception:
                 self.persistence = None
 
         # Buffer circulaire des interactions les plus r√©centes pour les modules
         # comme le SemanticConceptExtractor ou l'EmotionEngine qui ont besoin
         # d'acc√©der rapidement √† l'historique court terme sans interroger tout
         # le syst√®me de m√©moire hi√©rarchique.
         self._recent_memories: "deque[Dict[str, Any]]" = deque(maxlen=1000)
         # Compatibilit√© avec les anciens composants qui acc√®dent directement √†
         # l'attribut `memories`.
         self.memories = self._recent_memories
 
         architecture = self.cognitive_architecture
         self._preferences = getattr(architecture, "preferences", None) if architecture else None
+        self.phenomenal_journal = getattr(architecture, "phenomenal_journal", None) if architecture else None
+        self.phenomenal_recall = getattr(architecture, "phenomenal_recall", None) if architecture else None
 
         self._salience_scorer = None
         if ENABLE_SALIENCE_SCORER and SalienceScorer:
             try:
                 self._salience_scorer = SalienceScorer(
                     emotion_engine=getattr(architecture, "emotions", None) if architecture else None,
                     reward_engine=getattr(architecture, "reward_engine", None) if architecture else None,
                     goals=getattr(architecture, "goals", None) if architecture else None,
                     preferences=self._preferences,
                 )
             except Exception:
                 self._salience_scorer = None
 
         self.manager = None
         if ENABLE_SUMMARIZER and _ConceptMemoryManager:
             try:
                 self.manager = _ConceptMemoryManager(self, architecture=architecture)
             except Exception:
                 self.manager = None
 
         try:
             self.retrieval = MemoryRetrieval(
                 salience_scorer=self._salience_scorer,
                 preferences=self._preferences,
             )
@@ -269,51 +274,50 @@ class MemorySystem:
             self.metacognition = getattr(self.cognitive_architecture, "metacognition", None)
         else:
             self.reasoning = None
             self.perception = None
             self.emotions = None
             self.goals = None
             self.metacognition = None
 
         if self.salience_scorer is not None:
             self.salience_scorer.goals = getattr(self, "goals", None)
             if self.prefs_bridge and not self.salience_scorer.prefs:
                 self.salience_scorer.prefs = self.prefs_bridge
 
         summarizer = getattr(self.persistence, "summarizer", None)
         belief_graph = getattr(self.cognitive_architecture, "beliefs", None) if self.cognitive_architecture else None
         self_model_ref = getattr(self.cognitive_architecture, "self_model", None) if self.cognitive_architecture else None
         self.long_horizon = LongTermMemoryHub(
             self.store,
             summarizer=summarizer,
             belief_graph=belief_graph,
             self_model=self_model_ref,
             goals=getattr(self, "goals", None),
         )
         self._refresh_long_horizon_bindings()
 
-        
         # === M√âMOIRE SENSORIELLE ===
         self.sensory_memory = {
             "iconic": {
                 "buffer": [],
                 "duration": 0.5,  # 500ms comme chez l'humain
                 "capacity": 12
             },
             "echoic": {
                 "buffer": [],
                 "duration": 3.0,  # 3 secondes
                 "capacity": 8
             }
         }
         
         # === M√âMOIRE DE TRAVAIL ===
         decay_candidates = (0.2, 0.4, 0.6, 0.8)
         self._decay_schedulers = {
             name: ThompsonBetaScheduler(decay_candidates)
             for name in ("phonological_loop", "visuospatial_sketchpad", "episodic_buffer")
         }
 
         self.working_memory = {
             "phonological_loop": {
                 "contents": [],
                 "capacity": 4,
@@ -407,50 +411,64 @@ class MemorySystem:
         )
         self._memory_feedback_history: "deque[Dict[str, Any]]" = deque(maxlen=512)
         self._parameter_drift_log: "deque[Dict[str, Any]]" = deque(maxlen=512)
         
         # === PROCESSUS DE CONSOLIDATION ===
         self.consolidation_process = {
             "active_consolidation": [],
             "reconsolidation_events": [],
             "sleep_cycles_completed": 0,
             "last_consolidation_time": time.time()
         }
         
         # === INDEX DE R√âCUP√âRATION ===
         self.retrieval_indexes = {
             "temporal": {},      # Index temporel
             "contextual": {},    # Index contextuel
             "emotional": {},     # Index √©motionnel
             "semantic": {}       # Index s√©mantique
         }
         
         # === CONNAISSANCES INN√âES ===
         self._initialize_innate_memories()
 
         print("üíæ Syst√®me de m√©moire initialis√©")
 
+    def set_phenomenal_sources(
+        self,
+        *,
+        journal: Optional["PhenomenalJournal"] = None,
+        recall: Optional["PhenomenalRecall"] = None,
+    ) -> "MemorySystem":
+        """Bind or refresh phenomenal journal integrations at runtime."""
+
+        if journal is not None:
+            self.phenomenal_journal = journal
+        if recall is not None:
+            self.phenomenal_recall = recall
+        return self
+
     def add(self, item: Dict[str, Any]) -> str:
         """Ajoute un item dans le store s√©mantique externe et d√©clenche la consolidation."""
 
         if self.store is None:
             raise RuntimeError("Aucun memory_store n'est configur√© pour ce MemorySystem")
 
         item_id = self.store.add_item(item)
         if self.manager is not None:
             try:
                 self.manager.on_new_items()
             except Exception:
                 pass
         return item_id
 
     def add_memory(
         self,
         entry_or_kind: Any,
         content: Any = None,
         metadata: Optional[Dict[str, Any]] = None,
         *,
         tags: Optional[Iterable[str]] = None,
         **extra_metadata: Any,
     ) -> Dict[str, Any]:
         """Interface unifi√©e pour stocker un souvenir dans le ``MemoryStore``.
 
@@ -1221,51 +1239,96 @@ class MemorySystem:
             self._recent_memories.append(recent_entry)
 
             # Feed RAG 5‚òÖ automatiquement (si pr√©sent)
             try:
                 arch = getattr(self, "cognitive_architecture", None)
                 if arch is not None and getattr(arch, "rag", None) is not None:
                     txt = recent_entry.get("text")
                     if txt:
                         arch.rag.add_document(
                             recent_entry.get("id", f"mem#{int(recent_entry.get('ts',0))}"),
                             txt,
                             meta={"ts": recent_entry.get("ts"), "source_trust": 0.6}
                         )
             except Exception:
                 # ne bloque jamais la m√©moire
                 pass
         except Exception:
             # La collecte r√©cente ne doit jamais interrompre l'encodage principal.
             pass
 
     def get_recent_memories(self, n: int = 100) -> List[Dict[str, Any]]:
         """Retourne les souvenirs les plus r√©cents encod√©s par le syst√®me."""
 
         if n <= 0:
             return []
-        return list(self._recent_memories)[-n:]
+        combined: List[Dict[str, Any]] = list(self._recent_memories)[-n:]
+        extras = self._phenomenal_recent_entries(n)
+        if extras:
+            combined.extend(extras)
+            combined.sort(key=lambda item: float(item.get("ts") or item.get("timestamp") or 0.0))
+        if len(combined) > n:
+            combined = combined[-n:]
+        return combined
+
+    def _phenomenal_recent_entries(self, limit: int) -> List[Dict[str, Any]]:
+        journal = getattr(self, "phenomenal_journal", None)
+        if journal is None or not hasattr(journal, "tail") or limit <= 0:
+            return []
+        try:
+            episodes = journal.tail(limit=limit)
+        except Exception:
+            return []
+        entries: List[Dict[str, Any]] = []
+        seen_ids = set()
+        for ep in episodes:
+            if not isinstance(ep, Mapping):
+                continue
+            summary = str(ep.get("summary") or "").strip()
+            if not summary:
+                continue
+            episode_id = ep.get("id") or ep.get("episode_id")
+            if episode_id and episode_id in seen_ids:
+                continue
+            if episode_id:
+                seen_ids.add(episode_id)
+            entry = {
+                "id": episode_id,
+                "kind": ep.get("kind", "phenomenal_episode"),
+                "text": summary,
+                "ts": float(ep.get("ts", 0.0)),
+                "source": "phenomenal_journal",
+                "episode": ep,
+            }
+            if ep.get("mode"):
+                entry["mode"] = ep.get("mode")
+            if isinstance(ep.get("values"), list) and ep.get("values"):
+                entry["values"] = list(ep.get("values"))
+            if isinstance(ep.get("emotions"), Mapping):
+                entry["emotions"] = dict(ep.get("emotions"))
+            entries.append(entry)
+        return entries
     
     def _generate_memory_id(self, content: Any, context: Dict, timestamp: float) -> str:
         """G√©n√®re un ID unique pour une m√©moire"""
         content_hash = hashlib.md5(str(content).encode()).hexdigest()[:8]
         context_hash = hashlib.md5(str(context).encode()).hexdigest()[:8]
         timestamp_str = str(int(timestamp * 1000))[-6:]
         
         return f"{content_hash}_{context_hash}_{timestamp_str}"
     
     def _update_retrieval_indexes(self, memory_trace: MemoryTrace):
         """Met √† jour les index de r√©cup√©ration"""
         
         # Index temporel
         time_key = self._get_temporal_key(memory_trace.timestamp)
         if time_key not in self.retrieval_indexes["temporal"]:
             self.retrieval_indexes["temporal"][time_key] = []
         self.retrieval_indexes["temporal"][time_key].append(memory_trace.id)
         
         # Index contextuel
         for context_key, context_value in memory_trace.context.items():
             context_str = f"{context_key}:{context_value}"
             if context_str not in self.retrieval_indexes["contextual"]:
                 self.retrieval_indexes["contextual"][context_str] = []
             self.retrieval_indexes["contextual"][context_str].append(memory_trace.id)
         
@@ -1718,56 +1781,173 @@ class MemorySystem:
             # Suppression de la m√©moire
             del self.long_term_memory[memory_type][memory_id]
             
             # Mise √† jour des m√©tadonn√©es
             self.memory_metadata["total_memories"] -= 1
             
             print(f"üóëÔ∏è M√©moire oubli√©e: {memory_id}")
     
     def _remove_from_indexes(self, memory_id: str):
         """Supprime une m√©moire de tous les index"""
         # Index temporel
         for time_key, memories in self.retrieval_indexes["temporal"].items():
             if memory_id in memories:
                 memories.remove(memory_id)
         
         # Index contextuel
         for context_key, memories in self.retrieval_indexes["contextual"].items():
             if memory_id in memories:
                 memories.remove(memory_id)
         
         # Index √©motionnel
         for emotion_key, memories in self.retrieval_indexes["emotional"].items():
             if memory_id in memories:
                 memories.remove(memory_id)
     
+    def _phenomenal_autobiographical_stream(self, limit: int = 120) -> Optional[Dict[str, Any]]:
+        journal = getattr(self, "phenomenal_journal", None)
+        if journal is None or not hasattr(journal, "tail"):
+            return None
+        try:
+            episodes = journal.tail(limit=limit)
+        except Exception:
+            return None
+        if not episodes:
+            return None
+
+        selected: List[Dict[str, Any]] = []
+        values_set = set()
+        principles_set = set()
+        valence_series: List[float] = []
+        arousal_series: List[float] = []
+        seen_ids = set()
+
+        for raw in episodes:
+            if not isinstance(raw, Mapping):
+                continue
+            summary = str(raw.get("summary") or "").strip()
+            if not summary:
+                continue
+            kind = str(raw.get("kind") or "")
+            if kind not in {"action", "emotion", "mode", "reflection", "doubt", "audit"}:
+                continue
+            episode_id = str(raw.get("id") or raw.get("episode_id") or "")
+            if episode_id and episode_id in seen_ids:
+                continue
+            if episode_id:
+                seen_ids.add(episode_id)
+            extras: List[str] = []
+            vals = raw.get("values")
+            if isinstance(vals, (list, tuple)):
+                kept = [str(val) for val in vals if isinstance(val, str)]
+                if kept:
+                    values_set.update(kept)
+                    extras.append("valeurs=" + ", ".join(kept[:3]))
+            principles = raw.get("principles")
+            if isinstance(principles, (list, tuple)):
+                kept = [str(val) for val in principles if isinstance(val, str)]
+                if kept:
+                    principles_set.update(kept)
+                    extras.append("principes=" + ", ".join(kept[:3]))
+            emotions = raw.get("emotions") if isinstance(raw.get("emotions"), Mapping) else raw.get("emotions")
+            if isinstance(emotions, Mapping):
+                primary = emotions.get("primary") or emotions.get("label")
+                valence = emotions.get("valence")
+                arousal = emotions.get("arousal")
+                if isinstance(primary, str) and primary:
+                    extras.append(f"√©motion={primary}")
+                if isinstance(valence, (int, float)):
+                    valence_series.append(float(valence))
+                if isinstance(arousal, (int, float)):
+                    arousal_series.append(float(arousal))
+            context = raw.get("context") if isinstance(raw.get("context"), Mapping) else {}
+            metrics = context.get("metrics") if isinstance(context, Mapping) else {}
+            if isinstance(metrics, Mapping):
+                highlight = []
+                for key in ("priority", "uncertainty", "sj_reward", "calibration_gap"):
+                    value = metrics.get(key)
+                    if isinstance(value, (int, float)):
+                        highlight.append(f"{key}={value:.2f}")
+                if highlight:
+                    extras.append("; ".join(highlight))
+            body = raw.get("body") if isinstance(raw.get("body"), Mapping) else {}
+            if isinstance(body, Mapping):
+                homeo = body.get("homeostasis")
+                if isinstance(homeo, Mapping) and homeo:
+                    top_drive = next(iter(homeo.items()))
+                    try:
+                        extras.append(f"drive {top_drive[0]}={float(top_drive[1]):.2f}")
+                    except Exception:
+                        pass
+            line = summary
+            if extras:
+                line = f"{summary} ({' | '.join(extras)})"
+            selected.append({
+                "ts": float(raw.get("ts", 0.0)),
+                "text": line,
+            })
+
+        if not selected:
+            return None
+        selected.sort(key=lambda item: item["ts"])
+        lines = [item["text"] for item in selected]
+        timestamps = [item["ts"] for item in selected]
+        if len(timestamps) > 1:
+            gaps = [max(0.0, min(1.0, (b - a) / 3_600.0)) for a, b in zip(timestamps, timestamps[1:])]
+            coherence = 1.0 - (sum(gaps) / len(gaps))
+        else:
+            coherence = 1.0
+        coherence = max(0.0, min(1.0, coherence))
+
+        result: Dict[str, Any] = {
+            "narrative": "\n".join(lines),
+            "coherence": coherence,
+            "episodes": len(lines),
+            "source": "phenomenal_journal",
+        }
+        if values_set:
+            result["values"] = sorted(values_set)
+        if principles_set:
+            result["principles"] = sorted(principles_set)
+        if valence_series or arousal_series:
+            span: Dict[str, Tuple[float, float]] = {}
+            if valence_series:
+                span["valence"] = (min(valence_series), max(valence_series))
+            if arousal_series:
+                span["arousal"] = (min(arousal_series), max(arousal_series))
+            result["emotion_span"] = span
+        return result
+
     def form_autobiographical_narrative(self) -> Dict[str, Any]:
+        phenomenal_story = self._phenomenal_autobiographical_stream()
+        if phenomenal_story is not None:
+            return phenomenal_story
         """
         Forme un r√©cit autobiographique √† partir des m√©moires √©pisodiques
         """
         episodic_memories = list(self.long_term_memory[MemoryType.EPISODIC].values())
-        
+
         if not episodic_memories:
             return {"narrative": "Aucune exp√©rience m√©morable encore.", "coherence": 0.0}
         
         # Tri chronologique
         episodic_memories.sort(key=lambda x: x.timestamp)
         
         # Extraction des √©v√©nements significatifs
         significant_events = [
             mem for mem in episodic_memories 
             if mem.strength > 0.7 or abs(mem.valence) > 0.6
         ]
         
         # Construction du r√©cit
         narrative_parts = []
         total_coherence = 0.0
         
         for i, event in enumerate(significant_events):
             event_description = self._describe_memory_event(event)
             narrative_parts.append(event_description)
             
             # Calcul de la coh√©rence avec l'√©v√©nement pr√©c√©dent
             if i > 0:
                 prev_event = significant_events[i-1]
                 coherence = self._calculate_temporal_coherence(prev_event, event)
                 total_coherence += coherence
