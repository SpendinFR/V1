diff a/AIVIKI-main/AGI_Evolutive/cognition/reflection_loop.py b/AIVIKI-main/AGI_Evolutive/cognition/reflection_loop.py	(rejected hunks)
@@ -8,57 +8,71 @@ from AGI_Evolutive.utils.llm_service import (
     get_llm_manager,
     is_llm_enabled,
 )
 
 
 LOGGER = logging.getLogger(__name__)
 
 
 def _llm_enabled() -> bool:
     return is_llm_enabled()
 
 
 def _llm_manager():
     return get_llm_manager()
 
 class ReflectionLoop:
     """
     Boucle réflexive périodique (mini "inner monologue").
     """
     def __init__(self, meta_cog, interval_sec: int = 300):
         self.meta = meta_cog
         self.interval = max(30, int(interval_sec))
         self.running = False
         self._thread: Optional[threading.Thread] = None
         self._last_llm_reflection: Optional[Mapping[str, Any]] = None
+        self._last_phenomenal_signature: Optional[tuple] = None
 
     def start(self):
         if self.running: return
         self.running = True
         def loop():
             while self.running:
                 try:
+                    preview = self._phenomenal_preview()
+                    if preview and preview.get("narrative"):
+                        signature = tuple(
+                            str(ep.get("id") or ep.get("episode_id") or idx)
+                            for idx, ep in enumerate(preview.get("episodes", []))
+                            if isinstance(ep, Mapping)
+                        ) or (str(int(preview.get("ts", time.time()))),)
+                        if signature != self._last_phenomenal_signature:
+                            self.meta.log_inner_monologue(
+                                preview["narrative"],
+                                tags=["phenomenal", "recall"],
+                            )
+                            self._last_phenomenal_signature = signature
                     a = self.meta.assess_understanding()
                     gaps = []
                     for d in a["domains"].values():
                         gaps.extend(d.get("gaps", []))
                     self.meta.log_inner_monologue(
                         f"Auto-bilan: incertitude={a['uncertainty']:.2f}, gaps={gaps[:3]}",
                         tags=["autonomy","metacognition"]
                     )
                     self.meta.propose_learning_goals(max_goals=2)
                 except Exception as e:
                     self.meta.log_inner_monologue(f"Reflection loop error: {e}", tags=["error"])
                 time.sleep(self.interval)
         self._thread = threading.Thread(target=loop, daemon=True)
         self._thread.start()
 
     def stop(self):
         self.running = False
 
     def _llm_generate_hypotheses(
         self,
         observation: Optional[str],
         recent: List[Dict[str, Any]],
         max_tests: int,
     ) -> Optional[Dict[str, Any]]:
         if not observation or not _llm_enabled():
@@ -205,25 +219,63 @@ class ReflectionLoop:
                             "counterexample": counterexample,
                         }
                     )
             except Exception:
                 hypotheses = []
 
         if not hypotheses:
             fallback_label = observation or scratch.get("reason") or "hypothèse_manquante"
             hypotheses = [
                 {
                     "label": str(fallback_label),
                     "score": 0.4,
                     "explanation": "Fallback généré faute d'abduction.",
                     "ask_next": None,
                     "counterexample": None,
                 }
             ]
 
         hypotheses = hypotheses[:max_tests]
         contradicted = sum(1 for h in hypotheses if h.get("counterexample"))
         summary = (
             f"{len(hypotheses)} hypothèse(s) testée(s), {contradicted} contre-exemple(s) détecté(s)."
         )
 
         return {"tested": len(hypotheses), "hypotheses": hypotheses, "summary": summary}
+
+    def _phenomenal_preview(self) -> Optional[Dict[str, Any]]:
+        journal = getattr(self.meta, "phenomenal_journal", None)
+        recall = getattr(self.meta, "phenomenal_recall", None)
+        architecture = getattr(self.meta, "architecture", None) or getattr(self.meta, "arch", None)
+        if architecture is not None:
+            if journal is None:
+                journal = getattr(architecture, "phenomenal_journal", None)
+            if recall is None:
+                recall = getattr(architecture, "phenomenal_recall", None)
+        preview: Optional[Dict[str, Any]] = None
+        if recall is not None and hasattr(recall, "immersive_preview"):
+            try:
+                preview = recall.immersive_preview()
+            except Exception:
+                preview = None
+        if (preview is None or not preview.get("narrative")) and journal is not None and hasattr(journal, "tail"):
+            try:
+                episodes = journal.tail(limit=6)
+            except Exception:
+                episodes = []
+            if episodes:
+                try:
+                    lines = journal.narrativize(episodes)
+                except Exception:
+                    lines = [
+                        str(ep.get("summary") or "")
+                        for ep in episodes
+                        if isinstance(ep, Mapping)
+                    ]
+                preview = {
+                    "episodes": episodes,
+                    "narrative": "\n".join(line for line in lines if line),
+                    "ts": time.time(),
+                }
+        if preview and "episodes" not in preview:
+            preview["episodes"] = []
+        return preview
